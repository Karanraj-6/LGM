{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPFLw9tU5_fG"
      },
      "source": [
        "\n",
        "**TASK - PREDICT THE NEXT CHARACTER OF WORD OR WORD OF THE SENTENCE**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRtRTQhz5_fJ"
      },
      "source": [
        "Importing necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q9QLGQmy5_fJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "np.random.seed(42)\n",
        "import tensorflow as tf\n",
        "tf.random.set_seed(42)\n",
        "import warnings as wg\n",
        "wg.filterwarnings(\"ignore\")\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Activation, Dropout, RepeatVector, TimeDistributed, Embedding\n",
        "from tensorflow.keras.optimizers import  RMSprop\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle\n",
        "import heapq\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1_HAS4L25_fK"
      },
      "source": [
        "**Loading Data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "klQa6KJq5_fK",
        "outputId": "4184394b-06a8-4672-bc9e-ac66152dd2d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "corpus length: 581888\n"
          ]
        }
      ],
      "source": [
        "data= open(\"/content/Next Word Prediction Dataset.txt\", encoding=\"utf8\").read().lower()\n",
        "print('corpus length:', len(data))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYvJY2FO5_fL"
      },
      "source": [
        "**Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U16X0IDs5_fL",
        "outputId": "600e4a6b-5ec8-46f5-95ef-8d145fb08e82"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "unique chars: 73\n"
          ]
        }
      ],
      "source": [
        "character = sorted(list(set(data)))\n",
        "char_indices = dict((c, i) for i, c in enumerate(character))\n",
        "indices_char = dict((i, c) for i, c in enumerate(character))\n",
        "\n",
        "print(f'unique chars: {len(character)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zDsN5Iu95_fL",
        "outputId": "adce90db-8171-436a-e242-f504a29e625a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num training examples: 193950\n"
          ]
        }
      ],
      "source": [
        "seq_len = 40\n",
        "step = 3\n",
        "sentences = []\n",
        "next_chars = []\n",
        "for i in range(0, len(data) - seq_len, step):\n",
        "    sentences.append(data[i: i + seq_len ])\n",
        "    next_chars.append(data[i + seq_len])\n",
        "print(f'num training examples: {len(sentences)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HeBITD675_fL",
        "outputId": "415dc320-169e-49f8-d54c-ba324a75e5f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'e'"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X = np.zeros((len(sentences), seq_len, len(character)), dtype=np.bool)\n",
        "y = np.zeros((len(sentences), len(character)), dtype=np.bool)\n",
        "for i, sentence in enumerate(sentences):\n",
        "    for t, char in enumerate(sentence):\n",
        "        X[i, t, char_indices[char]] = 1\n",
        "    y[i, char_indices[next_chars[i]]] = 1\n",
        "\n",
        "sentences[124]\n",
        "next_chars[100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GWPep85a5_fL",
        "outputId": "32384fde-9c6e-4f9b-e00f-d60a80faf641"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "        True])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X[0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DyHCyNlu5_fL",
        "outputId": "2dbb531c-d8f3-47e9-f93c-ef50c1015017"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False,  True, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False, False, False, False, False, False, False, False, False,\n",
              "       False])"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "df8yfdBv5_fM",
        "outputId": "2c903405-fb1e-463b-b8f3-26d64a662115"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(193950, 40, 73)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nhVQlV2f5_fM",
        "outputId": "f75db910-f6af-4721-c6a4-45281da516a0"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(193950, 73)"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "y.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvHPN17P5_fM"
      },
      "source": [
        "**Developing model and training it using the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4HbxxwOV5_fM",
        "outputId": "cbd7e25e-10fa-437b-b282-f858027e8f28"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28917"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "total_words = len(tokenizer.word_index) + 1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nMT54qAA5_fM",
        "outputId": "0dff54ce-374f-46b9-ddc8-81cfdc0ad9b0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm_19 (LSTM)              (None, 500)               1148000   \n",
            "                                                                 \n",
            " dense_19 (Dense)            (None, 73)                36573     \n",
            "                                                                 \n",
            " activation_11 (Activation)  (None, 73)                0         \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1184573 (4.52 MB)\n",
            "Trainable params: 1184573 (4.52 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Creating the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(500, input_shape=(seq_len, len(character))))\n",
        "model.add(Dense(len(character)))\n",
        "model.add(Activation('softmax'))\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mu48AggI5_fM",
        "outputId": "bcd7db54-fc6b-422a-cfb3-57622fe640ff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n",
            "6061/6061 [==============================] - 2007s 331ms/step - loss: 2.1130 - accuracy: 0.3863\n",
            "Epoch 2/5\n",
            "6061/6061 [==============================] - 1965s 324ms/step - loss: 1.6558 - accuracy: 0.5030\n",
            "Epoch 3/5\n",
            "6061/6061 [==============================] - 2065s 341ms/step - loss: 1.4592 - accuracy: 0.5562\n",
            "Epoch 4/5\n",
            "6061/6061 [==============================] - 2149s 355ms/step - loss: 1.3224 - accuracy: 0.5922\n",
            "Epoch 5/5\n",
            "6061/6061 [==============================] - 2298s 379ms/step - loss: 1.2069 - accuracy: 0.6228\n"
          ]
        }
      ],
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(X, y, epochs = 5, verbose=1)\n",
        "model.save('nextword.h5')\n",
        "pickle.dump(history, open(\"history.p\", \"wb\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lTmecmMn5_fN"
      },
      "source": [
        "**Defining all the functions needed for the predictions**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JuKjbseI5_fN"
      },
      "outputs": [],
      "source": [
        "def prepare_input(text):\n",
        "    x = np.zeros((1, seq_len, len(character)))\n",
        "    for t, char in enumerate(text):\n",
        "        x[0, t, char_indices[char]] = 1.\n",
        "\n",
        "    return x\n",
        "\n",
        "\n",
        "#functions to get next probable characters\n",
        "def sample(preds, top_n=3):\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds)\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "\n",
        "    return heapq.nlargest(top_n, range(len(preds)), preds.take)\n",
        "\n",
        "def predict_completion(text, max_length=400):\n",
        "    original_text = text\n",
        "    generated = text\n",
        "    completion = ''\n",
        "\n",
        "    # Generate text until reaching the maximum length or a space character\n",
        "    while len(original_text + completion) < max_length:\n",
        "        x = prepare_input(text)\n",
        "        preds = model.predict(x, verbose=0)[0]\n",
        "        next_index = sample(preds, top_n=1)[0]\n",
        "        next_char = indices_char[next_index]\n",
        "        text = text[1:] + next_char\n",
        "        completion += next_char\n",
        "\n",
        "        # If a space is encountered, return the completion\n",
        "        if next_char == ' ':\n",
        "            return completion\n",
        "\n",
        "    return completion\n",
        "\n",
        "def predict_completions(text, n=3):\n",
        "    x = prepare_input(text)\n",
        "    preds = model.predict(x, verbose=0)[0]\n",
        "    next_indices = sample(preds, n)\n",
        "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_FF84AEr5_fN"
      },
      "outputs": [],
      "source": [
        "labels = [\"With great power comes great responsibility.\", \"India's diversity weaves a tapestry of innovation and influence across the globe.\",\n",
        "\"In a world of magic and wonder, Harry Potter taught us the strength of friendship and courage.\", \"Sachin's bat carved not just records, but a legacy of cricketing devotion.\",\n",
        "\"Artificial Intelligence is the silent revolution reshaping our present and defining our future.\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KVUEfhn25_fN",
        "outputId": "52520374-734a-40bd-8a5e-59473b5af8ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "with great power comes great responsibil\n",
            "['ity ', 'less ', 'ate ', ' the ', '\\nthe ']\n",
            "\n",
            "india's diversity weaves a tapestry of i\n",
            "['nterest ', 't. ', 'mpression. ', ' trust ', '\\nto ']\n",
            "\n",
            "in a world of magic and wonder, harry po\n",
            "['ints ', 'liced ', 'ssible ', 'or ', 'wn ']\n",
            "\n",
            "sachin's bat carved not just records, bu\n",
            "['t ', 'ring ', 's ', 'c ', 'liness ']\n",
            "\n",
            "artificial intelligence is the silent re\n",
            "['adon\\nwhich ', 'spertaining ', 'd ', 'periesce ', 'ceived ']\n",
            "\n"
          ]
        }
      ],
      "source": [
        "for i in labels:\n",
        "    seq = i[:40].lower()\n",
        "    print(seq)\n",
        "    print(predict_completions(seq, 5))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_-10n9H5_fN"
      },
      "source": [
        "**Printing the loss and accuracy of the model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5xuRDojO5_fN",
        "outputId": "a4135237-5220-4c5f-e394-3aa39132dd3a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6061/6061 [==============================] - 990s 163ms/step - loss: 1.0360 - accuracy: 0.6764\n",
            "Test Loss 1.0359888076782227\n",
            "Test Accuracy 0.6763702034950256\n"
          ]
        }
      ],
      "source": [
        "loss, acc = model.evaluate(X,y)\n",
        "print(\"Test Loss\", loss)\n",
        "print(\"Test Accuracy\", acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y5IeGlJ5_fN"
      },
      "source": [
        "**Conclusion**\\\n",
        "*In this task, I have built a text generation model using LSTM that can predict the possible next word in a sequence based on the provided text dataset. The model was trained using TensorFlow/Keras and involved tokenizing the text, creating input sequences, and training an LSTM-based neural network. I have also used the trained model, demonstrating its ability to produce coherent sequences of words.*"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}